from __future__ import annotations

import math
import re
from dataclasses import dataclass
from typing import Optional, List, Dict, Any, Tuple
from collections import deque

from PySide6.QtCore import QObject, Signal, Slot, QMutex, QMutexLocker
from rapidfuzz.distance import Levenshtein

# -----------------------------------------
# Êï∞ÊçÆÁªìÊûÑÔºà‰øùÊåÅ‰∏éÂéüÊé•Âè£‰∏ÄËá¥Ôºâ
# -----------------------------------------

@dataclass
class MatchProposal:
    target_cue: Any
    confidence_score: float
    strategy_source: str  # "SPRTHead"
    matched_words: List[str]
    matched_phonemes: List[str]

    @classmethod
    def create_empty_proposal(cls) -> "MatchProposal":
        return cls(
            target_cue=type("EmptyCue", (), {"id": -1, "character": None, "line": ""})(),
            confidence_score=0.0,
            strategy_source="None",
            matched_words=[],
            matched_phonemes=[],
        )

@dataclass
class TargetEntry:
    head_tok: List[str]
    head_phonemes: List[str]
    head_bigrams: List[Tuple[str, str]]
    # NEW: Êï¥Âè• n-gramÔºàÁî®‰∫éÈîöÁÇπÊïëÊè¥Ôºâ
    line_ngrams_tok: List[Tuple[str, ...]]
    line_ngrams_ph: List[Tuple[str, ...]]
    line_ngram_index: Dict[Tuple[str, ...], int]  # ‰ΩçÁΩÆÁ¥¢ÂºïÔºåÁî®‰∫é head-bias

# -----------------------------------------
# ÂÆûÁî®ÂáΩÊï∞
# -----------------------------------------

_TOKEN_SPLIT_RE = re.compile(r"[^\w\s\u00C0-\u017F\u0100-\u024F\u1E00-\u1EFF'-]")

STOPWORDS = {
    "le","la","les","du","de","des","un","une","et","a","√†","au","aux","en","y",
    "ou","pour","par","sur","dans","que","qui","quoi","ou","o√π","je","tu","il","elle",
    "nous","vous","ils","elles","me","te","se","ne","pas","mais","donc","or","ni","car",
    "l","d","j","qu","ce","cet","cette","ces","mon","ma","mes","ton","ta","tes","son","sa","ses"
}
FILLERS = {"hum", "euh", "uh", "mmm"}

def _norm_tokenize(text: str) -> List[str]:
    cleaned = _TOKEN_SPLIT_RE.sub(" ", text.lower())
    toks = [t for t in cleaned.split() if t]
    return toks

def _bigrams(tokens: List[str]) -> List[Tuple[str, str]]:
    return list(zip(tokens, tokens[1:])) if len(tokens) >= 2 else []

def _ngrams(tokens: List[str], n: int) -> List[Tuple[str, ...]]:
    if n <= 1 or len(tokens) < n:
        return []
    return [tuple(tokens[i:i+n]) for i in range(0, len(tokens) - n + 1)]

def _clip(x: float, lo: float = 0.05, hi: float = 0.95) -> float:
    return max(lo, min(hi, x))

def _canon(s: str) -> str:
    # ËßÑËåÉÂΩ¢ÔºöÂéªÊéâÈªèËøûÁ¨¶Âè∑ÔºåÁªü‰∏ÄÂ∞èÂÜô
    return re.sub(r"[‚Äô'\-]", "", s.lower())

def _split_clitic(word: str) -> List[str]:
    # NEW: Ê≥ïËØ≠Áº©ÂêàÁ≤óÊãÜÂàÜÔºön'avez -> [n, avez]; c'est -> [c, est]; qu'est-ce -> [qu, est, ce]
    w = word.replace("‚Äô", "'")
    parts = [p for p in re.split(r"'", w) if p]
    out: List[str] = []
    for p in parts:
        out.extend(_norm_tokenize(p))  # ÂÜçËøá‰∏ÄÊ¨°ËßÑËåÉÂåñÔºåÂéªÊ†áÁÇπ
    return out or (_norm_tokenize(word) or [word.lower()])

# -----------------------------------------
# SPRT ÂØπÈΩêÂô®ÔºàÂè™Áî® head + line-ngram ÈîöÁÇπÔºâ
# -----------------------------------------

class Aligner(QObject):
    """
    SPRT È©±Âä®ÁöÑÂØπÈΩêÂô®ÔºàÂè™Âà§ÂÆö‚ÄúÊòØÂê¶ËøõÂÖ•‰∏ã‰∏ÄÂè•‚ÄùÔºå‰∏ªË¶Å‰ΩøÁî®ÊØèË°å head_* ÁâπÂæÅÔºõ
    Êñ∞Â¢ûÔºöÂà©Áî®Êï¥Âè• line_ngram ÂÅöÈîöÁÇπÊïëÊè¥ÔºåÂÆπÈîôÊºèËØç„ÄÇÔºâ
    """

    standby = Signal()
    suggestionReady = Signal(object)
    currentCueIndexChanged = Signal(int)

    def __init__(self, cues: List[Any], g2p_converter: Any, parent: Optional[QObject] = None, debug: bool = False):
        super().__init__(parent)
        self.cues = cues
        self.g2p = g2p_converter
        self.debug = debug

        # ÈÖçÁΩÆÔºàÂèØÊåâÈúÄË∞ÉÂèÇÔºâ
        self.config: Dict[str, Any] = {
            # ASR Á™óÂè£‰∏é head ÂØπÈΩê
            "ASR_MIN_WORDS": 1,
            "HEAD_MAX_WORDS": 5,

            # SPRT ÈòàÂÄºÔºàÂØπÊï∞‰ººÁÑ∂Ôºâ‰∏éËøûÁª≠Á°ÆËÆ§
            "SPRT_A_ON": 2.2,
            "SPRT_B_OFF": -3.0,
            "CONFIRM_FRAMES": 2,
            "LLR_DECAY": 0.90,

            # Âà§ÂÆöÈó®Êßõ
            "ON_PROB_MIN": 0.55,
            "PHON_EQ_THR": 0.85,

            # ÁâπÂæÅÊùÉÈáç
            "W_PREFIX": 0.35,
            "W_BIGRAM": 0.25,
            "W_RARE":   0.20,
            "W_PHON":   0.20,

            # üîÅ ÈáçÂ§çÂè•Â§¥Á∞áÔºàÂø´ÈÄöÈÅìÔºâ
            "REPEAT_CLUSTER_ENABLE": True,
            "REPEAT_CLUSTER_PREFIX_N": 2,
            "REPEAT_CLUSTER_LOOKAHEAD": 2,
            "SPRT_A_ON_REPEAT": 2.0,
            "CONFIRM_FRAMES_REPEAT": 1,

            # ‚úÖ È¶ñËØçÊäïÁ•®ÊªëÁ™óÔºà‰ªÖÂú®ÈáçÂ§çÁ∞áÂÜÖÂêØÁî®Ôºâ
            "FIRSTWORD_WINDOW_ENABLE": True,
            "FIRSTWORD_WINDOW_W": 8,
            "FIRSTWORD_WINDOW_K": 3,
            "FIRSTWORD_WINDOW_MIN_LLR": 1.2,

            # NEW: line-ngram ÈîöÁÇπ
            "LINE_NGRAM_N": 3,        # ÂØπÈΩêÊâÄÁî®ÁöÑ n
            "W_ANCHOR": 0.30,         # ÈîöÁÇπÊùÉÈáçÂä†ÂÖ• S
            "ANCHOR_HEAD_BIAS": 0.5,  # Ë∂äÈù†ÂâçÊùÉÈáçË∂äÈ´òÔºàÂ∞æÈÉ®Ëá≥Â∞ë‰πò‰ª• 1-0.5=0.5Ôºâ
        }

        # Áä∂ÊÄÅ
        self.current_cue_index: int = -1
        self._mutex = QMutex()
        self._entry: Optional[TargetEntry] = None
        self._next_index: Optional[int] = None

        # SPRT Á¥ØËÆ°Áä∂ÊÄÅ
        self._llr: float = 0.0
        self._consec_on: int = 0
        self._last_prob: float = 0.5

        # ÈáçÂ§çÂè•Â§¥Á∞áÁä∂ÊÄÅ & È¶ñËØçÊªëÁ™ó
        self._in_repeat_cluster: bool = False
        self._firstword_hits: Optional[deque] = deque(maxlen=self.config["FIRSTWORD_WINDOW_W"]) \
            if self.config["FIRSTWORD_WINDOW_ENABLE"] else None

        # ÂÖ®Ââß IDF
        self._idf: Dict[str, float] = self._build_idf()

        self._refresh_target()
        if self.debug:
            print(f"[Aligner/SPRT] Init done. IDF size={len(self._idf)} next={self._next_index} repeat={self._in_repeat_cluster}")

    # -------------------- Â§ñÈÉ®Êé•Âè£ --------------------

    @Slot(int)
    def update_current_cue_index(self, index: int):
        with QMutexLocker(self._mutex):
            if index != self.current_cue_index:
                self.current_cue_index = index
                self._reset_sprt()
                self._refresh_target()
                if self.debug:
                    print(f"[Aligner/SPRT] current_cue_index -> {index}; next={self._next_index} repeat={self._in_repeat_cluster}")
                self.currentCueIndexChanged.emit(index)
            else:
                self._refresh_target()
                if self.debug:
                    print(f"[Aligner/SPRT] current index unchanged; refreshed next={self._next_index} repeat={self._in_repeat_cluster}")

    @Slot(list)
    def analyze(self, asr_word_list: List[str]):
        """Êé•Êî∂ÊúÄËøëÁ™óÂè£ÁöÑ ASR ËØçÂ∫èÂàóÔºåËøõË°å‰∏ÄÊ¨° SPRT Êõ¥Êñ∞„ÄÇ"""
        pending_proposal = None
        pending_index_change = None
        
        with QMutexLocker(self._mutex):
            if self._entry is None or self._next_index is None:
                return

            # ===(0) È¢ÑÂ§ÑÁêÜÔºöÁîüÊàêËßÑËåÉÂåñ ASR Â∫èÂàóÔºàÁî®‰∫éÈîöÁÇπÂåπÈÖçÔºâ===
            n = int(self.config.get("LINE_NGRAM_N", 3))
            W_norm: List[str] = []
            for w in asr_word_list:
                if not w or w.lower() in FILLERS:
                    continue
                # Áº©ÂêàÊãÜÂàÜ + ËßÑËåÉÂåñ
                for p in _split_clitic(w.lower()):
                    W_norm.append(p)
            W_norm = [t for t in W_norm if t]  # already normalized

            # ===(1) ÂèñÁõÆÊ†á head ‰∏é line-ngram===
            H_tok = self._entry.head_tok
            H_pho = self._entry.head_phonemes
            H_bi  = self._entry.head_bigrams
            L_tri = self._entry.line_ngrams_tok
            L_tri_ph = self._entry.line_ngrams_ph
            L_idx = self._entry.line_ngram_index

            m = min(self.config["HEAD_MAX_WORDS"], len(H_tok))
            Hm_tok = H_tok[:m]
            Hm_pho = H_pho[:m] if H_pho else []
            Hm_bi  = [b for b in H_bi if b[0] in set(Hm_tok)]  # ÁÆÄÂçïË£ÅÂâ™

            # ===(2) Âü∫‰∫é head ÁöÑ‰øùÁïôÔºàËÄÅÈÄªËæëÔºâ===
            W_raw = [w.lower() for w in asr_word_list if w]
            W_raw = [w for w in W_raw if w not in FILLERS]

            if W_raw:
                try:
                    W_raw_pho = self._words_to_phonemes(W_raw)
                except Exception:
                    W_raw_pho = ["" for _ in W_raw]
            else:
                W_raw_pho = []

            Hm_tok_pho = Hm_pho if Hm_pho else []
            PH_THR = self.config.get("PHON_EQ_THR", 0.85)
            Hm_canon = [_canon(t) for t in Hm_tok]

            W: List[str] = []
            for w, w_ph in zip(W_raw, W_raw_pho):
                wc = _canon(w)
                keep = (w in Hm_tok)
                if not keep:
                    keep = any(h in wc or wc in h for h in Hm_canon)
                if not keep and Hm_tok_pho and w_ph:
                    keep = any(Levenshtein.normalized_similarity(w_ph, hp) >= PH_THR for hp in Hm_tok_pho)
                if keep:
                    W.append(w)

            # ===(2b) ÈîöÁÇπÊïëÊè¥ÔºöËã• head ËøáÊª§ÂêéËØÅÊçÆËøáÂº±ÔºåÁî® line_ngram ÂëΩ‰∏≠Êù•ÂõûÂ°´===
            anchor_hit = False
            anchor_bias = 0.0
            anchor_words: List[str] = []
            if n >= 2 and W_norm:
                W_ng = _ngrams(W_norm, n)
                if L_tri:
                    # Áî®ËßÑËåÉÂΩ¢ÂÅöÂ≠óÂÖ∏ÂåπÈÖç
                    canon_target = {tuple(_canon(t) for t in tri): idx for (tri, idx) in L_idx.items()}
                    for tri in W_ng:
                        key = tuple(_canon(t) for t in tri)
                        if key in canon_target:
                            anchor_hit = True
                            anchor_words = list(tri)
                            # ‰ΩçÁΩÆË∂äÈù†ÂâçÔºåbias Ë∂äÂ§ß
                            pos = canon_target[key]
                            total = max(1, len(L_tri) - 1)
                            head_bias = 1.0 - (pos / total) * self.config["ANCHOR_HEAD_BIAS"]
                            anchor_bias = max(0.5, head_bias)  # ÊúÄ‰Ωé 0.5ÔºàË°åÂ∞æ‰πüÊúâÂàÜÔºâ
                            break

                # Ëã•ËØçÈù¢ÈîöÁÇπÊ≤°‰∏≠ÔºåÂ∞ùËØïÈü≥Á¥†ÈîöÁÇπ
                if not anchor_hit and L_tri_ph:
                    try:
                        W_ph = self._words_to_phonemes(W_norm)
                    except Exception:
                        W_ph = []
                    W_ng_ph = list(zip(*[W_ph[i:] for i in range(n)])) if len(W_ph) >= n else []
                    if W_ng_ph:
                        # ÈÄê‰∏™ n-gram ÂÅöÈü≥Á¥†Áõ∏‰ººÂåπÈÖç
                        thr = self.config.get("PHON_EQ_THR", 0.85)
                        for i, tri_ph in enumerate(W_ng_ph):
                            for j, tgt_ph in enumerate(L_tri_ph):
                                ok = True
                                for a, b in zip(tri_ph, tgt_ph):
                                    if Levenshtein.normalized_similarity(a, b) < thr:
                                        ok = False
                                        break
                                if ok:
                                    anchor_hit = True
                                    anchor_words = list(W_norm[i:i+n])
                                    total = max(1, len(L_tri_ph) - 1)
                                    head_bias = 1.0 - (j / total) * self.config["ANCHOR_HEAD_BIAS"]
                                    anchor_bias = max(0.5, head_bias)
                                    break
                            if anchor_hit:
                                break

            # ÂΩì head ËøáÊª§‰∏∫Á©∫/Âçï‰∏ÄÈùûÈ¶ñËØçÊó∂ÔºåÁî®ÈîöÁÇπÂõûÂ°´
            if not W or (len(W) == 1 and not any(_canon(W[0]) == _canon(Hm_tok[0]) for _ in [0] if Hm_tok)):
                if anchor_hit and anchor_words:
                    if self.debug:
                        print(f"[Aligner/SPRT] anchor rescue: {anchor_words} (bias={anchor_bias:.2f})")
                    W = anchor_words[:]  # Áî®ÈîöÁÇπÁâáÊÆµÂñÇÂÖ•ÁâπÂæÅ
                else:
                    # ‰ªçÁÑ∂Êó†ËØÅÊçÆÔºåË∑≥Ëøá
                    if not W:
                        if self.debug:
                            print("[Aligner/SPRT] no head-overlap; skip update")
                            print(f"[Aligner/SPRT] target head={Hm_tok} bigrams={Hm_bi} idx={self._next_index}")
                        if self._firstword_hits is not None:
                            self._firstword_hits.append(0)
                        return
                    if len(W) == 1:
                        if self.debug:
                            print("[Aligner/SPRT] single non-head token; skip update", W)
                            print(f"[Aligner/SPRT] target head={Hm_tok} bigrams={Hm_bi} idx={self._next_index}")
                        if self._firstword_hits is not None:
                            self._firstword_hits.append(0)
                        return

            # ===(3) ÁâπÂæÅ===
            if self.debug:
                print(f"[Aligner/SPRT] target head={Hm_tok} bigrams={Hm_bi} idx={self._next_index}")
            feats = self._features(W, Hm_tok, Hm_pho, Hm_bi)

            # ÂêàÊàêÂàÜÊï∞ + ÈîöÁÇπÂä†Êàê
            S = (self.config["W_PREFIX"] * feats["prefix_tok"] +
                 self.config["W_BIGRAM"] * feats["bigram_hit"] +
                 self.config["W_RARE"]   * feats["rare_norm"] +
                 self.config["W_PHON"]   * feats["phon_prefix"])
            if anchor_hit:
                S += self.config["W_ANCHOR"] * anchor_bias
            p_t = _clip(S)
            self._last_prob = p_t

            # SPRT Êõ¥Êñ∞ÔºàÂ∏¶Ë°∞ÂáèÔºâ
            self._llr = self._llr * self.config["LLR_DECAY"] + math.log(p_t) - math.log(1 - p_t)

            if self.debug:
                dbg = f"[Aligner/SPRT] W={W} | feats={feats} | "
                if anchor_hit:
                    dbg += f"anchor=1 bias={anchor_bias:.2f} | "
                dbg += f"S={S:.3f} p={p_t:.3f} llr={self._llr:.2f}"
                print(dbg)

            # ËøûÁª≠Á°ÆËÆ§
            on_prob = self.config.get("ON_PROB_MIN", 0.60)
            if p_t >= on_prob:
                self._consec_on += 1
            else:
                self._consec_on = 0

            # ËÆ∞ÂΩïÈ¶ñËØçÊªëÁ™ó
            first_match = False
            if Hm_tok:
                try:
                    W_sel_pho = self._words_to_phonemes(W)
                except Exception:
                    W_sel_pho = ["" for _ in W]
                first_tok = Hm_tok[0]
                first_pho = Hm_pho[0] if Hm_pho else ""
                first_match = any((_canon(w) == _canon(first_tok)) for w in W)
                if (not first_match) and first_pho:
                    PH_THR = self.config.get("PHON_EQ_THR", 0.85)
                    first_match = any(Levenshtein.normalized_similarity(p, first_pho) >= PH_THR for p in W_sel_pho if p)
            if self._firstword_hits is not None:
                self._firstword_hits.append(1 if first_match else 0)

            # ===(4) Âà§ÂÜ≥===
            if self._in_repeat_cluster:
                thr_on = self.config["SPRT_A_ON_REPEAT"]
                needed_frames = self.config["CONFIRM_FRAMES_REPEAT"]
            else:
                thr_on = self.config["SPRT_A_ON"]
                needed_frames = 1 if len(Hm_tok) <= 1 else self.config["CONFIRM_FRAMES"]

            if self._llr >= thr_on and self._consec_on >= needed_frames:
                pending_proposal = self._make_proposal(W, Hm_pho)
                if self.debug:
                    print(f"[Aligner/SPRT] SWITCH -> cue {self._next_index} (p={p_t:.2f}, llr={self._llr:.2f}) [sprt]")
                self.current_cue_index = self._next_index
                pending_index_change = self.current_cue_index
                self._reset_sprt()
                self._refresh_target()
            elif self._in_repeat_cluster and self._firstword_hits is not None:
                K = self.config["FIRSTWORD_WINDOW_K"]
                min_llr = self.config["FIRSTWORD_WINDOW_MIN_LLR"]
                hits = sum(self._firstword_hits)
                if hits >= K and self._llr >= min_llr:
                    pending_proposal = self._make_proposal(W, Hm_pho)
                    if self.debug:
                        print(f"[Aligner/SPRT] SWITCH -> cue {self._next_index} via firstword-window "
                              f"(hits={hits}/{len(self._firstword_hits)}, llr={self._llr:.2f})")
                    self.current_cue_index = self._next_index
                    pending_index_change = self.current_cue_index
                    self._reset_sprt()
                    self._refresh_target()
            elif self._llr <= self.config["SPRT_B_OFF"]:
                if self.debug:
                    print(f"[Aligner/SPRT] strong reject, reset (llr={self._llr:.2f})")
                self._reset_sprt()
        
        # ÈîÅÂ§ñÂèëÂ∞Ñ‰ø°Âè∑
        if pending_proposal is not None:
            if self.debug:
                print(f"[Aligner/SPRT] üîì Emitting suggestionReady signal outside lock")
            self.suggestionReady.emit(pending_proposal)
        
        if pending_index_change is not None:
            if self.debug:
                print(f"[Aligner/SPRT] üîì Emitting currentCueIndexChanged({pending_index_change}) signal outside lock")
            self.currentCueIndexChanged.emit(pending_index_change)

    # -------------------- ÂÜÖÈÉ®ÂÆûÁé∞ --------------------

    def _reset_sprt(self):
        self._llr = 0.0
        self._consec_on = 0
        self._last_prob = 0.5
        if self._firstword_hits is not None:
            self._firstword_hits.clear()

    def _refresh_target(self):
        """Âü∫‰∫é current_cue_index Âà∑Êñ∞‰∏ã‰∏ÄÂè• head Êù°ÁõÆÔºåÂπ∂‰ªé line_ngram ÊèêÂèñÂèØÈÖçÁΩÆÈïøÂ∫¶ÁöÑ n-gram„ÄÇ"""
        idx = self.current_cue_index + 1
        if idx < len(self.cues):
            cue = self.cues[idx]

            # head
            head_tok = cue.head_tok if getattr(cue, 'head_tok', None) else _norm_tokenize(getattr(cue, 'pure_line', cue.line))[:5]
            head_pho = cue.head_phonemes if getattr(cue, 'head_phonemes', None) else []
            head_bi  = _bigrams(head_tok)  # CHG: ‰∏çÂÜç‰æùËµñ head_ngramÔºåÁé∞ÁÆó

            # line n-gramÔºàNEWÔºâ
            n = int(self.config.get("LINE_NGRAM_N", 3))

            # ÂÖàÂ∞ùËØï‰ªé JSON ËØªÂèñ line_ngramÔºàÂèØËÉΩÂ∑≤ÁªèÊòØ n-gram ÂàóË°®Ôºå‰πüÂèØËÉΩÊòØÊï¥Âè• tokenÔºâ
            raw_ln = getattr(cue, 'line_ngram', None)
            line_tokens: List[str]
            if isinstance(raw_ln, list):
                if raw_ln and all(isinstance(x, (list, tuple)) for x in raw_ln):
                    # Â∑≤ÁªèÊòØ n-gram ÂàóË°®ÔºàÂèñ‰∏é n Áõ∏ÂêåÈïøÂ∫¶ÁöÑÔºâ
                    ln_tok = [tuple(t[:n]) for t in raw_ln if isinstance(t, (list, tuple)) and len(t) >= n]
                    line_tokens = []  # Êó†Ê≥ïÊÅ¢Â§çÊï¥Âè•ÔºåÂêéÁª≠‰ªÖÁî® n-gram
                elif raw_ln and all(isinstance(x, str) for x in raw_ln):
                    # ÊòØÊï¥Âè• token ÂàóË°®
                    line_tokens = [x.lower() for x in raw_ln]
                    ln_tok = _ngrams(line_tokens, n)
                else:
                    # Á©∫/Êú™Áü•ÔºåÈÄÄÂåñÂà∞‰ªé pure_line Ëß£Êûê
                    line_tokens = _norm_tokenize(getattr(cue, 'pure_line', cue.line))
                    ln_tok = _ngrams(line_tokens, n)
            else:
                # Ê≤°Êúâ line_ngram Â≠óÊÆµÔºö‰ªéÊï¥Âè•Ëß£Êûê
                line_tokens = _norm_tokenize(getattr(cue, 'pure_line', cue.line))
                ln_tok = _ngrams(line_tokens, n)

            # Èü≥Á¥† n-gramÔºàËã•ÂèØÔºâ
            try:
                if line_tokens:
                    ph_all = self._words_to_phonemes(line_tokens)
                    ln_ph = list(zip(*[ph_all[i:] for i in range(n)])) if len(ph_all) >= n else []
                else:
                    # Ëã•Âè™Êúâ n-gram ÂàóË°®‰ΩÜÊó†Êï¥Âè• tokensÔºåÂàôÊó†Ê≥ïÈáçÁÆóÈü≥Á¥†Ôºå‰øùÊåÅÁ©∫
                    ln_ph = []
            except Exception:
                ln_ph = []

            # Âª∫Á´ã‰ΩçÁΩÆÁ¥¢ÂºïÔºàÈù†ÂâçÁöÑ trigram Áªô‰∫àÊõ¥Â§ß biasÔºâ
            idx_map: Dict[Tuple[str, ...], int] = {}
            for i, tri in enumerate(ln_tok):
                key = tuple(_canon(t) for t in tri)
                if key not in idx_map:
                    idx_map[key] = i

            self._entry = TargetEntry(
                head_tok=head_tok,
                head_phonemes=head_pho,
                head_bigrams=head_bi,
                line_ngrams_tok=ln_tok,
                line_ngrams_ph=ln_ph,
                line_ngram_index=idx_map,
            )
            self._next_index = idx

            # Ê£ÄÊµãÈáçÂ§çÂè•Â§¥Á∞áÔºàÊ≤øÁî®ÊóßÈÄªËæëÔºâ
            self._in_repeat_cluster = False
            if self.config["REPEAT_CLUSTER_ENABLE"]:
                n_pref = min(self.config["REPEAT_CLUSTER_PREFIX_N"], len(head_tok))
                sig = tuple(_canon(t) for t in head_tok[:n_pref]) if n_pref > 0 else ()
                look = self.config["REPEAT_CLUSTER_LOOKAHEAD"]
                same_cnt = 0
                for j in range(1, look + 1):
                    k = idx + j
                    if k >= len(self.cues):
                        break
                    c = self.cues[k]
                    tok_k = c.head_tok if getattr(c, 'head_tok', None) else _norm_tokenize(getattr(c, 'pure_line', c.line))[:5]
                    sig_k = tuple(_canon(t) for t in tok_k[:n_pref]) if n_pref > 0 else ()
                    if sig and sig_k == sig:
                        same_cnt += 1
                self._in_repeat_cluster = (sig != () and same_cnt >= 1)

            if self.debug:
                print(f"[Aligner/SPRT] _refresh_target -> next={self._next_index}, head={head_tok}, "
                      f"line_ngram_n={n}, line_tris={len(ln_tok)}, repeat_cluster={self._in_repeat_cluster}")
        else:
            self._entry = None
            self._next_index = None
            self._in_repeat_cluster = False

    def _features(self, W: List[str], H_tok: List[str], H_pho: List[str], H_bi: List[Tuple[str, str]]) -> Dict[str, float]:
        # 1) ËØçÂ∫èÂâçÁºÄ
        k = len(W)
        if k == 0:
            prefix_tok = 0.0
        else:
            k_eff = min(k, len(H_tok))
            Wk = W[:k_eff]
            if H_pho:
                try:
                    W_pho_pos = self._words_to_phonemes(Wk)
                except Exception:
                    W_pho_pos = ["" for _ in Wk]
            else:
                W_pho_pos = ["" for _ in Wk]
            thr = self.config.get("PHON_EQ_THR", 0.85)
            match_cnt = 0
            for i in range(k_eff):
                tok_ok = (Wk[i] == H_tok[i]) or (_canon(Wk[i]) == _canon(H_tok[i]))
                pho_ok = False
                if H_pho and W_pho_pos[i] and H_pho[i]:
                    pho_ok = Levenshtein.normalized_similarity(W_pho_pos[i], H_pho[i]) >= thr
                if tok_ok or pho_ok:
                    match_cnt += 1
            prefix_tok = match_cnt / max(1, k_eff)

        # 2) bigram ÂëΩ‰∏≠ÔºàËØçÈù¢ OR Èü≥Á¥†Ôºâ
        W_bi_tok = set(_bigrams(W))
        tok_hit = bool(W_bi_tok and any(b in W_bi_tok for b in H_bi))

        pho_hit = 0.0
        if H_pho:
            try:
                W_pho_all = self._words_to_phonemes(W)
            except Exception:
                W_pho_all = []
            if len(W_pho_all) >= 2 and len(H_pho) >= 2:
                W_bi_ph = list(zip(W_pho_all, W_pho_all[1:]))
                H_bi_ph = list(zip(H_pho, H_pho[1:]))
                thr = self.config.get("PHON_EQ_THR", 0.85)
                for a1, a2 in W_bi_ph:
                    for b1, b2 in H_bi_ph:
                        if (Levenshtein.normalized_similarity(a1, b1) >= thr and
                            Levenshtein.normalized_similarity(a2, b2) >= thr):
                            pho_hit = 1.0
                            break
                    if pho_hit:
                        break
        bigram_hit = 1.0 if (tok_hit or pho_hit) else 0.0

        # 3) ÁΩïËßÅËØçÂëΩ‰∏≠ÔºàÂü∫‰∫é IDFÔºâ
        rare_head = sorted(H_tok, key=lambda t: self._idf.get(t, 1.0), reverse=True)[:2]
        rare_hits = sum(1 for w in W if w in rare_head)
        rare_norm = rare_hits / 2.0

        # 4) Èü≥Á¥†ÂâçÁºÄÁõ∏‰ººÔºàËã•Êó† phonemesÔºåÁΩÆ 0.5 ‰∏≠ÊÄßÔºâ
        if H_pho:
            try:
                W_pho = self._words_to_phonemes(W)
                k_eff2 = min(len(W_pho), len(H_pho))
                phon_prefix = Levenshtein.normalized_similarity(
                    " ".join(W_pho[:k_eff2]), " ".join(H_pho[:k_eff2])
                ) if k_eff2 > 0 else 0.0
            except Exception:
                phon_prefix = 0.5
        else:
            phon_prefix = 0.5

        return {
            "prefix_tok": float(prefix_tok),
            "bigram_hit": float(bigram_hit),
            "rare_norm": float(rare_norm),
            "phon_prefix": float(phon_prefix),
        }

    def _make_proposal(self, W: List[str], Hm_pho: List[str]) -> MatchProposal:
        try:
            W_pho = self._words_to_phonemes(W)
        except Exception:
            W_pho = [""] * len(W)

        target_cue = self.cues[self._next_index] if self._next_index is not None else None
        conf = self._p_from_llr(self._llr)
        return MatchProposal(
            target_cue=target_cue,
            confidence_score=conf,
            strategy_source="SPRTHead",
            matched_words=W,
            matched_phonemes=W_pho,
        )

    def _p_from_llr(self, llr: float) -> float:
        return 1.0 / (1.0 + math.exp(-llr))

    def _words_to_phonemes(self, words: List[str]) -> List[str]:
        if hasattr(self.g2p, "batch_convert"):
            return self.g2p.batch_convert(words)
        else:
            return [getattr(self.g2p, "convert", lambda x: x)(w) for w in words]

    # -------------------- IDF --------------------

    def _build_idf(self) -> Dict[str, float]:
        df: Dict[str, int] = {}
        N = max(1, len(self.cues))
        for cue in self.cues:
            text = getattr(cue, 'pure_line', '') or cue.line
            toks = set(_norm_tokenize(text))
            for t in toks:
                df[t] = df.get(t, 0) + 1
        return {t: math.log((N + 1) / (c + 1)) + 1.0 for t, c in df.items()}





