from typing import List
from .base import G2PConverter

try:
    from transformers import T5ForConditionalGeneration, AutoTokenizer
    import torch
    CHARSIU_AVAILABLE = True
except ImportError:
    T5ForConditionalGeneration = None
    AutoTokenizer = None
    torch = None
    CHARSIU_AVAILABLE = False

class CharsiuG2P(G2PConverter):
    """
    åŸºäº CharsiuG2P (ByT5) çš„å¤šè¯­è¨€ G2P è½¬æ¢å™¨
    æ”¯æŒ 100 ç§è¯­è¨€çš„å­—ç´ åˆ°éŸ³ç´ è½¬æ¢
    ä½¿ç”¨ Hugging Face Transformers å’Œé¢„è®­ç»ƒçš„ ByT5 æ¨¡å‹
    """
    
    def __init__(self, model_name: str = 'charsiu/g2p_multilingual_byT5_tiny_16_layers_100', language: str = 'eng-us'):
        """
        åˆå§‹åŒ– CharsiuG2P è½¬æ¢å™¨
        
        Args:
            model_name: é¢„è®­ç»ƒæ¨¡å‹åç§°ï¼Œå¯é€‰ï¼š
                       - 'charsiu/g2p_multilingual_byT5_tiny_8_layers_100'
                       - 'charsiu/g2p_multilingual_byT5_tiny_12_layers_100'
                       - 'charsiu/g2p_multilingual_byT5_tiny_16_layers_100' (é»˜è®¤)
                       - 'charsiu/g2p_multilingual_byT5_small_100'
            language: è¯­è¨€ä»£ç ï¼Œæ ¼å¼åŸºäº ISO-639ï¼Œä¾‹å¦‚ï¼š
                     - 'eng-us': ç¾å¼è‹±è¯­
                     - 'fra': æ³•è¯­
                     - 'deu': å¾·è¯­
                     - 'spa': è¥¿ç­ç‰™è¯­
                     - 'cmn': ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰
                     - 'jpn': æ—¥è¯­
                     - 'kor': éŸ©è¯­
        """
        if not CHARSIU_AVAILABLE:
            raise ImportError(
                "CharsiuG2P dependencies not available. Please install: "
                "pip install transformers torch"
            )
        
        self.model_name = model_name
        self.language = language
        self.device = 'cuda' if torch and torch.cuda.is_available() else 'cpu'
        
        print(f"[CharsiuG2P] Initializing model: {model_name}")
        print(f"[CharsiuG2P] Language: {language}")
        print(f"[CharsiuG2P] Device: {self.device}")
        
        try:
            # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
            if not CHARSIU_AVAILABLE:
                raise ImportError("Dependencies not available")
            self.model = T5ForConditionalGeneration.from_pretrained(model_name)  # type: ignore
            self.tokenizer = AutoTokenizer.from_pretrained('google/byt5-small')  # type: ignore
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            self.model.to(self.device)
            self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            
            print(f"[CharsiuG2P] Model loaded successfully")
            
        except Exception as e:
            print(f"[CharsiuG2P] Failed to load model: {e}")
            print(f"ğŸ’¡ æç¤º:")
            print(f"  â€¢ é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´")
            print(f"  â€¢ ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸")
            print(f"  â€¢ æ¨¡å‹å¤§å°çº¦å‡ ç™¾MBï¼Œè¯·ç¡®ä¿å­˜å‚¨ç©ºé—´å……è¶³")
            raise

    def convert(self, text: str) -> str:
        """
        è½¬æ¢å•ä¸ªæ–‡æœ¬å­—ç¬¦ä¸²ä¸ºéŸ³ç´ 
        
        Args:
            text: è¾“å…¥æ–‡æœ¬ï¼ˆå•è¯ï¼‰
            
        Returns:
            IPA éŸ³ç´ å­—ç¬¦ä¸²
        """
        if not text or not text.strip():
            return ""
        
        try:
            # æ·»åŠ è¯­è¨€å‰ç¼€ï¼ˆCharsiuG2P è¦æ±‚çš„æ ¼å¼ï¼‰
            formatted_text = f'<{self.language}>: {text.strip()}'
            
            # åˆ†è¯
            inputs = self.tokenizer(
                [formatted_text], 
                padding=True, 
                add_special_tokens=False, 
                return_tensors='pt'
            )
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆé¢„æµ‹
            with torch.no_grad():  # type: ignore
                preds = self.model.generate(
                    **inputs,
                    num_beams=1,  # è´ªå©ªè§£ç ï¼Œæ–‡æ¡£å»ºè®®ä¸ä½¿ç”¨æŸæœç´¢
                    max_length=50,
                    do_sample=False
                )
            
            # è§£ç ç»“æœ
            phonemes = self.tokenizer.batch_decode(
                preds.tolist(), 
                skip_special_tokens=True
            )[0]
            
            return phonemes.strip()
            
        except Exception as e:
            print(f"[CharsiuG2P] Error converting '{text}': {e}")
            # å¤±è´¥æ—¶è¿”å›åŸæ–‡æœ¬ä½œä¸ºåå¤‡
            return text.strip()

    def batch_convert(self, texts: List[str]) -> List[str]:
        """
        æ‰¹é‡è½¬æ¢æ–‡æœ¬åˆ—è¡¨ä¸ºéŸ³ç´ åˆ—è¡¨
        
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            IPA éŸ³ç´ å­—ç¬¦ä¸²åˆ—è¡¨
        """
        if not texts:
            return []
        
        try:
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            non_empty_texts = [text.strip() for text in texts if text.strip()]
            if not non_empty_texts:
                return [''] * len(texts)
            
            # æ‰¹é‡æ·»åŠ è¯­è¨€å‰ç¼€
            formatted_texts = [f'<{self.language}>: {text}' for text in non_empty_texts]
            
            # æ‰¹é‡åˆ†è¯
            inputs = self.tokenizer(
                formatted_texts,
                padding=True,
                add_special_tokens=False,
                return_tensors='pt'
            )
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # æ‰¹é‡ç”Ÿæˆé¢„æµ‹
            with torch.no_grad():  # type: ignore
                preds = self.model.generate(
                    **inputs,
                    num_beams=1,
                    max_length=50,
                    do_sample=False
                )
            
            # æ‰¹é‡è§£ç ç»“æœ
            phonemes_list = self.tokenizer.batch_decode(
                preds.tolist(),
                skip_special_tokens=True
            )
            
            # å¤„ç†åŸå§‹æ–‡æœ¬ä¸­çš„ç©ºç™½
            result = []
            non_empty_idx = 0
            for text in texts:
                if text.strip():
                    result.append(phonemes_list[non_empty_idx].strip())
                    non_empty_idx += 1
                else:
                    result.append('')
            
            return result
            
        except Exception as e:
            print(f"[CharsiuG2P] Error in batch conversion: {e}")
            # å¤±è´¥æ—¶é€ä¸ªè½¬æ¢ä½œä¸ºåå¤‡
            return [self.convert(text) for text in texts]
    
    def get_supported_languages(self) -> List[str]:
        """
        è·å–æ”¯æŒçš„è¯­è¨€ä»£ç åˆ—è¡¨
        
        Returns:
            æ”¯æŒçš„è¯­è¨€ä»£ç åˆ—è¡¨ï¼ˆéƒ¨åˆ†å¸¸ç”¨è¯­è¨€ï¼‰
        """
        # CharsiuG2P æ”¯æŒ 100 ç§è¯­è¨€ï¼Œè¿™é‡Œåˆ—å‡ºä¸€äº›å¸¸ç”¨çš„
        return [
            'eng-us',    # ç¾å¼è‹±è¯­
            'eng-uk',    # è‹±å¼è‹±è¯­
            'fra',       # æ³•è¯­
            'deu',       # å¾·è¯­
            'spa',       # è¥¿ç­ç‰™è¯­
            'ita',       # æ„å¤§åˆ©è¯­
            'por',       # è‘¡è„ç‰™è¯­
            'rus',       # ä¿„è¯­
            'cmn',       # ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰
            'jpn',       # æ—¥è¯­
            'kor',       # éŸ©è¯­
            'ara',       # é˜¿æ‹‰ä¼¯è¯­
            'hin',       # å°åœ°è¯­
            'tha',       # æ³°è¯­
            'vie',       # è¶Šå—è¯­
            'nld',       # è·å…°è¯­
            'swe',       # ç‘å…¸è¯­
            'nor',       # æŒªå¨è¯­
            'dan',       # ä¸¹éº¦è¯­
            'fin',       # èŠ¬å…°è¯­
            'pol',       # æ³¢å…°è¯­
            'ces',       # æ·å…‹è¯­
            'hun',       # åŒˆç‰™åˆ©è¯­
            'tur',       # åœŸè€³å…¶è¯­
            'heb',       # å¸Œä¼¯æ¥è¯­
        ]
    
    def change_language(self, new_language: str):
        """
        æ›´æ”¹ç›®æ ‡è¯­è¨€
        
        Args:
            new_language: æ–°çš„è¯­è¨€ä»£ç 
        """
        self.language = new_language
        print(f"[CharsiuG2P] Language changed to: {new_language}")
    
    def get_model_info(self) -> dict:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Returns:
            åŒ…å«æ¨¡å‹ä¿¡æ¯çš„å­—å…¸
        """
        return {
            'model_name': self.model_name,
            'language': self.language,
            'device': self.device,
            'supported_languages': len(self.get_supported_languages()),
            'architecture': 'ByT5 (Byte-level T5)',
            'parameters': 'Tiny/Small variants available',
            'multilingual': True
        }
    
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'model'):
            del self.model
        if torch and torch.cuda.is_available():
            torch.cuda.empty_cache()  # type: ignore
