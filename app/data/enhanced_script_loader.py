#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆå‰§æœ¬åŠ è½½å™¨
æ”¯æŒmetaè¯æ¡æ£€éªŒã€dataclassæ ¼å¼æ ¡éªŒã€éŸ³ç´ æ£€éªŒç­‰åŠŸèƒ½
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import asdict, is_dataclass
from datetime import datetime

from app.models.models import Meta, Style, Cue, SubtitleDocument
from app.core.g2p.base import G2PConverter


class ScriptValidationError(Exception):
    """å‰§æœ¬éªŒè¯é”™è¯¯"""
    pass


class EnhancedScriptLoader:
    """å¢å¼ºç‰ˆå‰§æœ¬åŠ è½½å™¨"""
    
    def __init__(self, g2p_converter: Optional[G2PConverter] = None):
        self.g2p_converter = g2p_converter
        self.validation_results = {}
        self.conversion_results = {}
        
    def load_script(self, filepath: str) -> Tuple[SubtitleDocument, Dict[str, Any]]:
        """
        åŠ è½½å‰§æœ¬æ–‡ä»¶
        
        Returns:
            Tuple[SubtitleDocument, Dict]: (åŠ è½½çš„æ–‡æ¡£, åŠ è½½æŠ¥å‘Š)
        """
        file_path = Path(filepath)
        if not file_path.exists():
            raise FileNotFoundError(f"å‰§æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
        print(f"ğŸ” å¼€å§‹åŠ è½½å‰§æœ¬: {file_path.name}")
        
        # 1. åŠ è½½JSONæ•°æ®
        raw_data = self._load_json(file_path)
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰metaè¯æ¡
        has_meta = self._check_meta_field(raw_data)
        
        if not has_meta:
            print("âš ï¸ æœªå‘ç°metaè¯æ¡ï¼Œè°ƒç”¨è½¬æ¢è„šæœ¬...")
            raw_data = self._convert_legacy_format(raw_data, file_path)
            
        # 3. è¿›è¡Œdataclassæ ¼å¼æ ¡éªŒ
        print("ğŸ” è¿›è¡Œdataclassæ ¼å¼æ ¡éªŒ...")
        document = self._validate_and_create_document(raw_data)
        
        # 4. æ£€æŸ¥éŸ³ç´ å¹¶è¿›è¡ŒG2På¤„ç†
        print("ğŸ” æ£€æŸ¥éŸ³ç´ æ•°æ®...")
        g2p_results = self._process_phonemes(document)
        
        # 5. ç”ŸæˆåŠ è½½æŠ¥å‘Š
        report = self._generate_load_report(document, g2p_results)
        
        print("âœ… å‰§æœ¬åŠ è½½å®Œæˆ")
        return document, report
        
    def _load_json(self, filepath: Path) -> Dict[str, Any]:
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… JSONæ–‡ä»¶åŠ è½½æˆåŠŸ: {len(str(data))} å­—ç¬¦")
            return data
        except json.JSONDecodeError as e:
            raise ScriptValidationError(f"JSONæ ¼å¼é”™è¯¯: {e}")
        except Exception as e:
            raise ScriptValidationError(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            
    def _check_meta_field(self, data: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰metaè¯æ¡"""
        has_meta = 'meta' in data
        if has_meta:
            print("âœ… å‘ç°metaè¯æ¡ï¼Œä½¿ç”¨æ–°æ ¼å¼")
        else:
            print("âš ï¸ æœªå‘ç°metaè¯æ¡ï¼Œæ£€æµ‹åˆ°æ—§æ ¼å¼")
        return has_meta
        
    def _convert_legacy_format(self, data: Dict[str, Any], filepath: Path) -> Dict[str, Any]:
        """è½¬æ¢æ—§æ ¼å¼åˆ°æ–°æ ¼å¼"""
        print("ğŸ”„ è½¬æ¢æ—§æ ¼å¼åˆ°æ–°æ ¼å¼...")
        
        # åˆ›å»ºé»˜è®¤metaä¿¡æ¯
        meta = {
            "title": filepath.stem,
            "author": "",
            "translator": "",
            "version": "1.0",
            "description": f"ä»æ—§æ ¼å¼è½¬æ¢: {filepath.name}",
            "language": [],
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat(),
            "license": ""
        }
        
        # åˆ›å»ºæ–°æ ¼å¼æ•°æ®
        new_data = {
            "meta": meta,
            "styles": {
                "default": {
                    "font": "Noto Sans",
                    "size": 42,
                    "color": "#FFFFFF",
                    "pos": "bottom"
                }
            },
            "cues": data.get("cues", [])
        }
        
        # æ£€æµ‹å¹¶æ·»åŠ è¯­è¨€ä¿¡æ¯
        languages = self._detect_languages(new_data["cues"])
        new_data["meta"]["language"] = languages
        
        print(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆï¼Œæ£€æµ‹åˆ°è¯­è¨€: {languages}")
        return new_data
        
    def _detect_languages(self, cues: List[Dict]) -> List[str]:
        """æ£€æµ‹å‰§æœ¬ä¸­çš„è¯­è¨€"""
        languages = set()
        
        for cue in cues:
            # æ£€æŸ¥translationå­—æ®µ
            if "translation" in cue and isinstance(cue["translation"], dict):
                languages.update(cue["translation"].keys())
                
        # æ·»åŠ åŸå§‹è¯­è¨€ï¼ˆå‡è®¾ä¸ºæ³•è¯­ï¼Œæ ¹æ®æ‚¨çš„å‰§æœ¬å†…å®¹ï¼‰
        if any("character" in cue and cue.get("line", "") for cue in cues):
            languages.add("fr")  # æ³•è¯­
            
        return sorted(list(languages))
        
    def _validate_and_create_document(self, data: Dict[str, Any]) -> SubtitleDocument:
        """éªŒè¯æ•°æ®æ ¼å¼å¹¶åˆ›å»ºæ–‡æ¡£å¯¹è±¡"""
        errors = []
        
        try:
            # éªŒè¯metaå­—æ®µ
            meta_data = data.get("meta", {})
            meta = Meta(**meta_data) if meta_data else Meta()
            
            # éªŒè¯styleså­—æ®µ
            styles_data = data.get("styles", {"default": {}})
            styles = {}
            for name, style_data in styles_data.items():
                try:
                    styles[name] = Style(**style_data)
                except Exception as e:
                    errors.append(f"æ ·å¼ '{name}' æ ¼å¼é”™è¯¯: {e}")
                    styles[name] = Style()  # ä½¿ç”¨é»˜è®¤æ ·å¼
                    
            # éªŒè¯cueså­—æ®µ
            cues_data = data.get("cues", [])
            cues = []
            
            for i, cue_data in enumerate(cues_data):
                try:
                    # å¤„ç†å¯èƒ½ç¼ºå¤±çš„å­—æ®µ
                    cue_dict = self._normalize_cue_data(cue_data, i)
                    cue = Cue(**cue_dict)
                    cues.append(cue)
                except Exception as e:
                    errors.append(f"å°è¯ {i+1} æ ¼å¼é”™è¯¯: {e}")
                    # åˆ›å»ºä¸€ä¸ªæœ€å°çš„æœ‰æ•ˆcue
                    cues.append(Cue(
                        id=i+1,
                        character=cue_data.get("character"),
                        line=cue_data.get("line", ""),
                        phonemes="",
                        notes=f"æ ¼å¼é”™è¯¯: {e}"
                    ))
                    
            if errors:
                print(f"âš ï¸ å‘ç° {len(errors)} ä¸ªæ ¼å¼é—®é¢˜ï¼š")
                for error in errors[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    print(f"   - {error}")
                if len(errors) > 5:
                    print(f"   ... è¿˜æœ‰ {len(errors)-5} ä¸ªé”™è¯¯")
                    
            document = SubtitleDocument(meta=meta, styles=styles, cues=cues)
            print(f"âœ… æ–‡æ¡£åˆ›å»ºæˆåŠŸ: {len(cues)} æ¡å°è¯")
            
            self.validation_results = {
                "total_cues": len(cues),
                "valid_cues": len([c for c in cues if c.line]),
                "errors": errors,
                "has_meta": True,
                "languages": document.get_all_languages()
            }
            
            return document
            
        except Exception as e:
            raise ScriptValidationError(f"æ–‡æ¡£åˆ›å»ºå¤±è´¥: {e}")
            
    def _normalize_cue_data(self, cue_data: Dict[str, Any], index: int) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–cueæ•°æ®ï¼Œè¡¥å……ç¼ºå¤±å­—æ®µ"""
        normalized = {
            "id": cue_data.get("id", index + 1),
            "character": cue_data.get("character"),
            "line": cue_data.get("line", ""),
            "phonemes": cue_data.get("phonemes", ""),
            "character_cue_index": cue_data.get("character_cue_index", -1),
            "translation": cue_data.get("translation", {}),
            "notes": cue_data.get("notes", ""),
            "style": cue_data.get("style", "default")
        }
        
        # ç¡®ä¿translationæ˜¯å­—å…¸
        if not isinstance(normalized["translation"], dict):
            normalized["translation"] = {}
            
        return normalized
        
    def _process_phonemes(self, document: SubtitleDocument) -> Dict[str, Any]:
        """å¤„ç†éŸ³ç´ æ•°æ®"""
        if not self.g2p_converter:
            print("âš ï¸ æœªæä¾›G2Pè½¬æ¢å™¨ï¼Œè·³è¿‡éŸ³ç´ å¤„ç†")
            return {"processed": 0, "skipped": len(document.cues), "errors": []}
            
        processed = 0
        skipped = 0
        errors = []
        
        # æ”¶é›†éœ€è¦G2På¤„ç†çš„å°è¯
        lines_to_process = []
        indices_to_process = []
        
        for i, cue in enumerate(document.cues):
            if not cue.line.strip():  # ç©ºå°è¯
                skipped += 1
                continue
                
            if not cue.phonemes or not cue.phonemes.strip():  # æ²¡æœ‰éŸ³ç´ 
                lines_to_process.append(cue.line)
                indices_to_process.append(i)
            else:
                print(f"   è·³è¿‡å·²æœ‰éŸ³ç´ çš„å°è¯ {cue.id}: '{cue.line[:30]}...'")
                skipped += 1
                
        if lines_to_process:
            print(f"ğŸ”„ å¯¹ {len(lines_to_process)} æ¡å°è¯è¿›è¡ŒG2Pè½¬æ¢...")
            
            try:
                # æ‰¹é‡G2Pè½¬æ¢
                phonemes_results = self.g2p_converter.batch_convert(lines_to_process)
                
                # æ›´æ–°cueå¯¹è±¡çš„éŸ³ç´ 
                for idx, phonemes in zip(indices_to_process, phonemes_results):
                    document.cues[idx].phonemes = phonemes
                    processed += 1
                    if processed <= 3:  # æ˜¾ç¤ºå‰3ä¸ªè½¬æ¢ç»“æœ
                        cue = document.cues[idx]
                        print(f"   âœ… {cue.id}: '{cue.line[:20]}...' -> '{phonemes[:30]}...'")
                        
                if processed > 3:
                    print(f"   ... è¿˜æœ‰ {processed-3} æ¡å°è¯å®Œæˆè½¬æ¢")
                    
            except Exception as e:
                error_msg = f"G2Pæ‰¹é‡è½¬æ¢å¤±è´¥: {e}"
                errors.append(error_msg)
                print(f"âŒ {error_msg}")
        else:
            print("âœ… æ‰€æœ‰å°è¯éƒ½å·²æœ‰éŸ³ç´ æ•°æ®")
            
        return {
            "processed": processed,
            "skipped": skipped,
            "errors": errors,
            "total": len(document.cues)
        }
        
    def _generate_load_report(self, document: SubtitleDocument, g2p_results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆåŠ è½½æŠ¥å‘Š"""
        report = {
            "file_info": {
                "title": document.meta.title,
                "author": document.meta.author,
                "version": document.meta.version,
                "languages": document.meta.language,
                "total_cues": len(document.cues)
            },
            "validation": self.validation_results,
            "g2p_processing": g2p_results,
            "summary": {
                "valid_cues": len([c for c in document.cues if c.line.strip()]),
                "empty_cues": len([c for c in document.cues if not c.line.strip()]),
                "cues_with_phonemes": len([c for c in document.cues if c.phonemes and c.phonemes.strip()]),
                "characters": len(set(c.character for c in document.cues if c.character)),
                "available_languages": document.get_all_languages()
            }
        }
        
        return report
        
    def print_load_report(self, report: Dict[str, Any]):
        """æ‰“å°åŠ è½½æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ å‰§æœ¬åŠ è½½æŠ¥å‘Š")
        print("="*60)
        
        # æ–‡ä»¶ä¿¡æ¯
        file_info = report["file_info"]
        print(f"ğŸ“ æ ‡é¢˜: {file_info['title']}")
        print(f"ğŸ‘¤ ä½œè€…: {file_info['author'] or 'æœªçŸ¥'}")
        print(f"ğŸ“… ç‰ˆæœ¬: {file_info['version']}")
        print(f"ğŸŒ è¯­è¨€: {', '.join(file_info['languages']) if file_info['languages'] else 'æœªæŒ‡å®š'}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        summary = report["summary"]
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»å°è¯æ•°: {file_info['total_cues']}")
        print(f"   æœ‰æ•ˆå°è¯: {summary['valid_cues']}")
        print(f"   ç©ºå°è¯: {summary['empty_cues']}")
        print(f"   å·²æœ‰éŸ³ç´ : {summary['cues_with_phonemes']}")
        print(f"   è§’è‰²æ•°é‡: {summary['characters']}")
        print(f"   å¯ç”¨è¯­è¨€: {', '.join(summary['available_languages']) if summary['available_languages'] else 'æ— '}")
        
        # G2På¤„ç†ç»“æœ
        g2p = report["g2p_processing"]
        if g2p["processed"] > 0 or g2p["errors"]:
            print(f"\nğŸ”¤ G2På¤„ç†ç»“æœ:")
            print(f"   å·²å¤„ç†: {g2p['processed']}")
            print(f"   å·²è·³è¿‡: {g2p['skipped']}")
            if g2p["errors"]:
                print(f"   é”™è¯¯: {len(g2p['errors'])}")
                for error in g2p["errors"][:3]:
                    print(f"     - {error}")
                    
        # éªŒè¯é—®é¢˜
        validation = report["validation"]
        if validation.get("errors"):
            print(f"\nâš ï¸ éªŒè¯é—®é¢˜: {len(validation['errors'])}")
            for error in validation["errors"][:3]:
                print(f"   - {error}")
                
        print("="*60)


def demo_enhanced_loader():
    """æ¼”ç¤ºå¢å¼ºç‰ˆåŠ è½½å™¨"""
    print("ğŸ§ª æ¼”ç¤ºå¢å¼ºç‰ˆå‰§æœ¬åŠ è½½å™¨\n")
    
    # å‡è®¾æœ‰G2Pè½¬æ¢å™¨
    from app.core.g2p.g2p_manager import G2PManager
    
    try:
        g2p_manager = G2PManager()
        g2p_converter = g2p_manager.get_current_engine()
    except:
        g2p_converter = None
        print("âš ï¸ G2Pè½¬æ¢å™¨ä¸å¯ç”¨ï¼Œå°†è·³è¿‡éŸ³ç´ å¤„ç†")
        
    loader = EnhancedScriptLoader(g2p_converter)
    
    # æµ‹è¯•æ–‡ä»¶è·¯å¾„
    test_file = "scripts/final_script.json"
    
    try:
        document, report = loader.load_script(test_file)
        loader.print_load_report(report)
        
        # æ˜¾ç¤ºå‰å‡ æ¡å°è¯
        print(f"\nğŸ“ å‰3æ¡å°è¯é¢„è§ˆ:")
        for i, cue in enumerate(document.cues[:3]):
            if cue.line.strip():
                print(f"   {cue.id}. {cue.character or '(èˆå°æç¤º)'}: {cue.line}")
                if cue.phonemes:
                    print(f"      éŸ³ç´ : {cue.phonemes[:50]}...")
                    
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")


if __name__ == "__main__":
    demo_enhanced_loader()
