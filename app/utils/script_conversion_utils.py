#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script Conversion Utilities
ä¸ºMiomué¡¹ç›®æä¾›å‰§æœ¬æ ¼å¼è½¬æ¢å’ŒéŸ³ç´ å¤„ç†åŠŸèƒ½
"""

import json
import re
from typing import List, Dict, Any, Tuple, Optional
from pathlib import Path
import sys
import os
import unicodedata

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
current_dir = Path(__file__).parent
if current_dir.name == 'utils':
    # å¦‚æœåœ¨utilsç›®å½•ä¸­
    sys.path.insert(0, str(current_dir.parent))
    sys.path.insert(0, str(current_dir.parent / "app"))
else:
    # å¦‚æœåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸­
    sys.path.insert(0, str(current_dir))
    sys.path.insert(0, str(current_dir / "app"))

try:
    from app.core.g2p.epitran_g2p import EpitranG2P
    G2P_AVAILABLE = True
except ImportError:
    EpitranG2P = None
    G2P_AVAILABLE = False


class ScriptConverter:
    """å‰§æœ¬è½¬æ¢å™¨ç±»ï¼Œæä¾›éŸ³ç´ è½¬æ¢å’Œn-gramç”ŸæˆåŠŸèƒ½"""
    
    def __init__(self, language: str = 'fra-Latn', use_fallback: bool = True):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            language: è¯­è¨€ä»£ç 
            use_fallback: å¦‚æœG2Pä¸å¯ç”¨ï¼Œæ˜¯å¦ä½¿ç”¨åå¤‡æ–¹æ¡ˆ
        """
        self.language = language
        self.use_fallback = use_fallback
        self.g2p = None
        self._fallback_mode = False
        
        if G2P_AVAILABLE and EpitranG2P:
            try:
                self.g2p = EpitranG2P(language=language)
                print(f"âœ… G2Pè½¬æ¢å™¨åˆå§‹åŒ–æˆåŠŸ ({language})")
            except Exception as e:
                print(f"âš ï¸ G2Pè½¬æ¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                if use_fallback:
                    print("ğŸ”„ å°†ä½¿ç”¨åå¤‡éŸ³ç´ è½¬æ¢æ–¹æ¡ˆ")
                    self._fallback_mode = True
                else:
                    raise
        else:
            if use_fallback:
                print("âš ï¸ Epitranä¸å¯ç”¨ï¼Œä½¿ç”¨åå¤‡éŸ³ç´ è½¬æ¢æ–¹æ¡ˆ")
                self._fallback_mode = True
            else:
                raise ImportError("Epitranåº“ä¸å¯ç”¨ä¸”æœªå¯ç”¨åå¤‡æ–¹æ¡ˆ")
    
    @staticmethod
    def clean_french_text(text: str) -> str:
        """
        æ¸…ç†æ³•è¯­æ–‡æœ¬ï¼Œå»é™¤æ ‡ç‚¹ç¬¦å·ä½†ä¿ç•™æ³•è¯­ç‰¹æ®Šå­—ç¬¦
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ä¿ç•™çš„æ³•è¯­ç‰¹æ®Šå­—ç¬¦
        french_special_chars = set('Ã Ã¡Ã¢Ã¤Ã§Ã¨Ã©ÃªÃ«Ã¯Ã®Ã´Ã¹ÃºÃ»Ã¼Ã¿Ã±Ã¦Å“Ã€ÃÃ‚Ã„Ã‡ÃˆÃ‰ÃŠÃ‹ÃÃÃ”Ã™ÃšÃ›ÃœÅ¸Ã‘Ã†Å’')
        
        # å»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä½†ä¿ç•™å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼å’Œæ³•è¯­ç‰¹æ®Šå­—ç¬¦
        cleaned_chars = []
        for char in text:
            if (char.isalnum() or 
                char.isspace() or 
                char in french_special_chars or
                unicodedata.category(char).startswith('L')):  # æ‰€æœ‰å­—æ¯ç±»å­—ç¬¦
                cleaned_chars.append(char)
            elif char in '-\'':  # ä¿ç•™è¿å­—ç¬¦å’Œæ’‡å·ï¼ˆæ³•è¯­å¸¸ç”¨ï¼‰
                cleaned_chars.append(char)
        
        # åˆå¹¶è¿ç»­ç©ºæ ¼
        cleaned_text = ''.join(cleaned_chars)
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        
        return cleaned_text
    
    def _simple_phoneme_fallback(self, text: str) -> str:
        """
        ç®€å•çš„éŸ³ç´ è½¬æ¢åå¤‡æ–¹æ¡ˆï¼ˆä¸»è¦é’ˆå¯¹æ³•è¯­ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            è¿‘ä¼¼éŸ³ç´ å­—ç¬¦ä¸²
        """
        if not text:
            return ""
        
        text = text.lower()
        
        # æ³•è¯­éŸ³ç´ æ˜ å°„è§„åˆ™
        replacements = {
            'qu': 'k',
            'ch': 'Êƒ',
            'j': 'Ê’',
            'gn': 'É²',
            'tion': 'sjÉ”Ìƒ',
            'eau': 'o',
            'au': 'o',
            'ou': 'u',
            'ai': 'É›',
            'ei': 'É›',
            'oi': 'wa',
            'an': 'É‘Ìƒ',
            'en': 'É‘Ìƒ',
            'in': 'É›Ìƒ',
            'on': 'É”Ìƒ',
            'un': 'Å“Ìƒ',
            'Ã¨': 'É›',
            'Ã©': 'e',
            'Ãª': 'É›',
            'Ã ': 'a',
            'Ã§': 's',
            'c': 'k',  # ç®€åŒ–å¤„ç†
            'x': 'ks',
        }
        
        result = text
        for old, new in replacements.items():
            result = result.replace(old, new)
        
        return result
    
    def convert_to_phonemes(self, text: str) -> str:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºéŸ³ç´ 
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            éŸ³ç´ å­—ç¬¦ä¸²
        """
        if not text or not text.strip():
            return ""
        
        if self._fallback_mode or not self.g2p:
            return self._simple_phoneme_fallback(text)
        else:
            try:
                return self.g2p.convert(text)
            except Exception as e:
                print(f"âš ï¸ éŸ³ç´ è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ: {e}")
                return self._simple_phoneme_fallback(text)
    
    @staticmethod
    def tokenize_text(text: str, clean_punctuation: bool = True) -> List[str]:
        """
        å°†æ–‡æœ¬åˆ†è¯ä¸ºtokenåˆ—è¡¨
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            clean_punctuation: æ˜¯å¦åœ¨åˆ†è¯å‰æ¸…ç†æ ‡ç‚¹ç¬¦å·
            
        Returns:
            tokenåˆ—è¡¨
        """
        if not text or not text.strip():
            return []
        
        # å¦‚æœéœ€è¦æ¸…ç†æ ‡ç‚¹ç¬¦å·ï¼Œå…ˆæ¸…ç†
        if clean_punctuation:
            text = ScriptConverter.clean_french_text(text)
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†è¯ï¼Œé’ˆå¯¹æ¸…ç†åçš„æ–‡æœ¬
        if clean_punctuation:
            # å¯¹äºæ¸…ç†åçš„æ–‡æœ¬ï¼Œåªéœ€è¦æŒ‰ç©ºæ ¼åˆ†è¯ï¼Œä¿ç•™è¿å­—ç¬¦
            tokens = re.findall(r'\S+', text.lower())
        else:
            # å¯¹äºåŸå§‹æ–‡æœ¬ï¼Œä¿ç•™æ ‡ç‚¹ç¬¦å·
            tokens = re.findall(r'\w+|[^\w\s]', text.lower())
        
        return [token for token in tokens if token.strip()]
    
    @staticmethod
    def create_ngrams(tokens: List[str], n: int = 3) -> List[Tuple[str, ...]]:
        """
        ä»tokenåˆ—è¡¨åˆ›å»ºn-gramå…ƒç»„åˆ—è¡¨
        
        Args:
            tokens: tokenåˆ—è¡¨
            n: n-gramçš„å¤§å°
            
        Returns:
            n-gramå…ƒç»„åˆ—è¡¨
        """
        if not tokens or len(tokens) < n:
            return []
        
        ngrams = []
        for i in range(len(tokens) - n + 1):
            ngram = tuple(tokens[i:i + n])
            ngrams.append(ngram)
        
        return ngrams
    
    @staticmethod
    def get_head_tail_tokens(tokens: List[str], head_size: int = 2, tail_size: int = 3) -> Tuple[List[str], List[str]]:
        """
        è·å–tokenåˆ—è¡¨çš„å¤´éƒ¨å’Œå°¾éƒ¨
        
        Args:
            tokens: tokenåˆ—è¡¨
            head_size: å¤´éƒ¨å¤§å°
            tail_size: å°¾éƒ¨å¤§å°
            
        Returns:
            (å¤´éƒ¨tokens, å°¾éƒ¨tokens)
        """
        if not tokens:
            return [], []
        
        head_tokens = tokens[:head_size] if len(tokens) >= head_size else tokens[:]
        tail_tokens = tokens[-tail_size:] if len(tokens) >= tail_size else tokens[:]
        
        return head_tokens, tail_tokens
    
    def process_cue(self, cue_data: Dict[str, Any], n: int = 3, head_size: int = 2, tail_size: int = 3) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªcueï¼Œæ·»åŠ éŸ³ç´ å’Œn-gramä¿¡æ¯
        
        Args:
            cue_data: åŸå§‹cueæ•°æ®
            n: n-gramå¤§å°
            head_size: å¤´éƒ¨tokenæ•°é‡
            tail_size: å°¾éƒ¨tokenæ•°é‡
            
        Returns:
            å¤„ç†åçš„cueæ•°æ®
        """
        # å¤åˆ¶åŸæœ‰æ•°æ®
        processed_cue = cue_data.copy()
        
        # è·å–å°è¯æ–‡æœ¬
        line = cue_data.get('line', '')
        
        # ç”Ÿæˆæ¸…ç†åçš„å°è¯ï¼ˆå»é™¤æ ‡ç‚¹ç¬¦å·ï¼‰
        pure_line = self.clean_french_text(line)
        processed_cue['pure_line'] = pure_line
        
        # éŸ³ç´ è½¬æ¢ï¼ˆä½¿ç”¨æ¸…ç†åçš„å°è¯ï¼‰
        phonemes = self.convert_to_phonemes(pure_line)
        processed_cue['phonemes'] = phonemes
        
        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        if 'translation' not in processed_cue:
            processed_cue['translation'] = {}
        if 'notes' not in processed_cue:
            processed_cue['notes'] = ""
        if 'style' not in processed_cue:
            processed_cue['style'] = "default"
        
        # TokenåŒ–ï¼ˆä½¿ç”¨æ¸…ç†åçš„å°è¯ï¼‰
        tokens = self.tokenize_text(pure_line, clean_punctuation=False)  # pure_lineå·²ç»æ¸…ç†è¿‡äº†
        
        # è·å–å¤´éƒ¨å’Œå°¾éƒ¨tokens
        head_tokens, tail_tokens = self.get_head_tail_tokens(tokens, head_size, tail_size)
        
        # å¤´éƒ¨å’Œå°¾éƒ¨éŸ³ç´ è½¬æ¢
        head_phonemes = [self.convert_to_phonemes(token) for token in head_tokens]
        tail_phonemes = [self.convert_to_phonemes(token) for token in tail_tokens]
        
        # æ·»åŠ æ–°å­—æ®µ
        processed_cue['head_tok'] = head_tokens
        processed_cue['head_phonemes'] = head_phonemes
        processed_cue['tail_tok'] = tail_tokens
        processed_cue['tail_phonemes'] = tail_phonemes
        
        # åˆ›å»ºn-grams
        head_ngrams = self.create_ngrams(head_tokens, n)
        tail_ngrams = self.create_ngrams(tail_tokens, n)
        head_ngram_phonemes = self.create_ngrams(head_phonemes, n)
        tail_ngram_phonemes = self.create_ngrams(tail_phonemes, n)
        
        processed_cue['head_ngram'] = head_ngrams
        processed_cue['tail_ngram'] = tail_ngrams
        processed_cue['head_ngram_phonemes'] = head_ngram_phonemes
        processed_cue['tail_ngram_phonemes'] = tail_ngram_phonemes
        
        return processed_cue
    
    def convert_script(self, 
                      input_file: str, 
                      output_file: str, 
                      n: int = 3, 
                      head_size: int = 2, 
                      tail_size: int = 3,
                      verbose: bool = True) -> bool:
        """
        è½¬æ¢å®Œæ•´çš„å‰§æœ¬æ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            n: n-gramå¤§å°
            head_size: å¤´éƒ¨tokenæ•°é‡
            tail_size: å°¾éƒ¨tokenæ•°é‡
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
            
        Returns:
            è½¬æ¢æ˜¯å¦æˆåŠŸ
        """
        try:
            # è¯»å–è¾“å…¥æ–‡ä»¶
            if verbose:
                print(f"ğŸ“– æ­£åœ¨è¯»å–è¾“å…¥æ–‡ä»¶: {input_file}")
            
            with open(input_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if 'cues' not in data:
                raise ValueError("è¾“å…¥æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ 'cues' å­—æ®µ")
            
            if verbose:
                print(f"ğŸ“ æ‰¾åˆ° {len(data['cues'])} ä¸ªå¯¹è¯æ¡ç›®")
            
            # å¤„ç†æ¯ä¸ªcue
            processed_cues = []
            for i, cue in enumerate(data['cues']):
                if verbose and (i + 1) % 10 == 0:
                    print(f"âš™ï¸ å¤„ç†è¿›åº¦: {i+1}/{len(data['cues'])}")
                
                processed_cue = self.process_cue(cue, n, head_size, tail_size)
                processed_cues.append(processed_cue)
            
            # æ„å»ºè¾“å‡ºæ•°æ® - åŒ…å«å®Œæ•´çš„æ–‡æ¡£ç»“æ„
            output_data = {}
            
            # å¤„ç† meta ä¿¡æ¯
            if 'meta' in data:
                output_data['meta'] = data['meta']
                if verbose:
                    print(f"ğŸ“‹ ä¿ç•™åŸæœ‰ meta ä¿¡æ¯")
            else:
                # åˆ›å»ºé»˜è®¤ meta ä¿¡æ¯
                from datetime import datetime
                default_meta = {
                    "title": Path(input_file).stem,
                    "author": "",
                    "translator": "",
                    "version": "1.0",
                    "description": f"è½¬æ¢è‡ª {Path(input_file).name}",
                    "language": ["fra-Latn"],
                    "created_at": datetime.now().isoformat(),
                    "updated_at": datetime.now().isoformat(),
                    "license": ""
                }
                output_data['meta'] = default_meta
                if verbose:
                    print(f"ğŸ“‹ åˆ›å»ºé»˜è®¤ meta ä¿¡æ¯")
            
            # å¤„ç† styles ä¿¡æ¯
            if 'styles' in data:
                output_data['styles'] = data['styles']
                if verbose:
                    print(f"ğŸ¨ ä¿ç•™åŸæœ‰ styles ä¿¡æ¯")
            else:
                # åˆ›å»ºé»˜è®¤ styles
                default_styles = {
                    "default": {
                        "font": "Noto Sans",
                        "size": 42,
                        "color": "#FFFFFF",
                        "pos": "bottom"
                    }
                }
                output_data['styles'] = default_styles
                if verbose:
                    print(f"ğŸ¨ åˆ›å»ºé»˜è®¤ styles ä¿¡æ¯")
            
            # æ·»åŠ å¤„ç†åçš„ cues
            output_data['cues'] = processed_cues
            
            # ä¿å­˜è¾“å‡ºæ–‡ä»¶
            if verbose:
                print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜è¾“å‡ºæ–‡ä»¶: {output_file}")
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            if verbose:
                print(f"âœ… è½¬æ¢æˆåŠŸï¼å¤„ç†äº† {len(processed_cues)} ä¸ªå¯¹è¯æ¡ç›®")
            
            return True
            
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def convert_script_dialogues_to_converted(input_file: str, 
                                        output_file: str, 
                                        language: str = 'fra-Latn',
                                        n: int = 2,
                                        head_size: int = 2,
                                        tail_size: int = 3,
                                        verbose: bool = True) -> bool:
    """
    ä¾¿æ·å‡½æ•°ï¼šå°†script_dialoguesè½¬æ¢ä¸ºscript_dialogues_convertedæ ¼å¼
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        language: è¯­è¨€ä»£ç 
        n: n-gramå¤§å°
        head_size: å¤´éƒ¨tokenæ•°é‡ 
        tail_size: å°¾éƒ¨tokenæ•°é‡
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        c
    Returns:
        è½¬æ¢æ˜¯å¦æˆåŠŸ
    """
    converter = ScriptConverter(language=language, use_fallback=True)
    return converter.convert_script(input_file, output_file, n, head_size, tail_size, verbose)


if __name__ == '__main__':
    # ç¤ºä¾‹ç”¨æ³•
    success = convert_script_dialogues_to_converted(
        'script_dialogues.json',
        'script_dialogues_converted.json',
        language='fra-Latn',
        n=2
    )
    
    if success:
        print("ğŸ‰ è½¬æ¢å®Œæˆï¼")
    else:
        print("âŒ è½¬æ¢å¤±è´¥ï¼")
